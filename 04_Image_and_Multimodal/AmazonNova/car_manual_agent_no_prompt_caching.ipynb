{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09c3cdab",
   "metadata": {},
   "source": [
    "# Let us implement an in-vehicle agent to assist drivers based on user manuals\n",
    "\n",
    "Amazon Nova is a new generation of multimodal understanding and creative content generation models that offer state-of-the-art quality, unparalleled customization, and the best price-performance. Amazon Nova models incorporate the same secure-by-design approach as all AWS services, with built-in controls for the safe and responsible use of AI.\n",
    "\n",
    "Amazon Nova has two categories of models: \n",
    " - **Understanding models** —These models are capable of reasoning over several input modalities, including text, video, and image, and output text. \n",
    "- **Creative Content Generation models** —These models generate images or videos based on a text or image prompt.\n",
    "  \n",
    "### Amazon Nova Models at Glance\n",
    "\n",
    "**Multimodal Understanding Models**\n",
    "- **Amazon Nova Micro**: Lightening fast, cost-effective text-only model\n",
    "- **Amazon Nova Lite**: Fastest, most affordable multimodal FM in the industry for its intelligence tier\n",
    "- **Amazon Nova Pro**:  The fastest, most cost-effective, state-of-the-art multimodal model in the industry\n",
    "\n",
    "**Creative Content Generation Models**\n",
    "- **Amazon Nova Canvas**:State-of-the-art image generation model\n",
    "- **Amazon Nova Reel**:State-of-the-art video generation model\n",
    "\n",
    "\n",
    "The following workshop will be focused primarily on Amazon Nova Understanding Models. \n",
    "\n",
    "**Amazon Nova Multimodal understanding** foundation models (FMs) are a family of models that are capable of reasoning over several input modalities, including text, video, documents and/or images, and output text. You can access these models through the Bedrock Converse API and InvokeModel API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aea9407",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Step 1: Gain Access to the Model**: If you have not yet requested for model access in Bedrock, you do so [request access following these instructions](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b8e0a-4874-402a-b765-7937bb9f1d78",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 When to Use What?\n",
    "\n",
    "## 2.1 When to Use Amazon Nova Micro Model\n",
    "\n",
    "Amazon Nova Micro (Text Input Only) is the fastest and most affordable option, optimized for large-scale, latency-sensitive deployments like conversational interfaces, chats, and high-volume tasks, such as classification, routing, entity extraction, and document summarization.\n",
    "\n",
    "## 2.2 When to Use Amazon Nova Lite Model\n",
    "\n",
    "Amazon Nova Lite balances intelligence, latency, and cost-effectiveness. It’s optimized for complex scenarios where low latency (minimal delay) is crucial, such as interactive agents that need to orchestrate multiple tool calls simultaneously. Amazon Nova Lite supports image, video, and text inputs and outputs text. \n",
    "\n",
    "## 2.3 When to Use Amazon Nova Pro Model\n",
    "Amazon Nova Pro is designed for highly complex use cases requiring advanced reasoning, creativity, and code generation. Amazon Nova pro supports image, video, and text inputs and outputs text. \n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Run the cells in this section to install the packages needed by the notebooks in this workshop. ⚠️ You will see pip dependency errors, you can safely ignore these errors. ⚠️\n",
    "\n",
    "_IGNORE ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1effee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3>=1.28.57\n",
      "  Using cached boto3-1.36.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting awscli>=1.29.57\n",
      "  Using cached awscli-1.37.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore>=1.31.57\n",
      "  Using cached botocore-1.36.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.28.57)\n",
      "  Using cached s3transfer-0.11.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli>=1.29.57)\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting PyYAML<6.1,>=3.10 (from awscli>=1.29.57)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli>=1.29.57)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli>=1.29.57)\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore>=1.31.57)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore>=1.31.57)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore>=1.31.57)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli>=1.29.57)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached boto3-1.36.0-py3-none-any.whl (139 kB)\n",
      "Using cached awscli-1.37.0-py3-none-any.whl (4.6 MB)\n",
      "Using cached botocore-1.36.0-py3-none-any.whl (13.3 MB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Using cached s3transfer-0.11.0-py3-none-any.whl (84 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, six, PyYAML, pyasn1, jmespath, docutils, colorama, rsa, python-dateutil, botocore, s3transfer, boto3, awscli\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.1\n",
      "    Uninstalling pyasn1-0.6.1:\n",
      "      Successfully uninstalled pyasn1-0.6.1\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.7.2\n",
      "    Uninstalling rsa-4.7.2:\n",
      "      Successfully uninstalled rsa-4.7.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.0\n",
      "    Uninstalling botocore-1.36.0:\n",
      "      Successfully uninstalled botocore-1.36.0\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.11.0\n",
      "    Uninstalling s3transfer-0.11.0:\n",
      "      Successfully uninstalled s3transfer-0.11.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.36.0\n",
      "    Uninstalling boto3-1.36.0:\n",
      "      Successfully uninstalled boto3-1.36.0\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.37.0\n",
      "    Uninstalling awscli-1.37.0:\n",
      "      Successfully uninstalled awscli-1.37.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "jupyter-ai 2.28.3 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.13.3 requires botocore<1.34.163,>=1.34.70, but you have botocore 1.36.0 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "langchain-aws 0.1.18 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.36.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.2 awscli-1.37.0 boto3-1.36.0 botocore-1.36.0 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 pyasn1-0.6.1 python-dateutil-2.9.0.post0 rsa-4.7.2 s3transfer-0.11.0 six-1.17.0 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2dc8edd-0a3b-4bd8-9e3f-c9fe9eaefaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ee402-ad79-495e-8adf-e7cb4bf02265",
   "metadata": {},
   "source": [
    "## Create the boto3 client\n",
    "\n",
    "Interaction with the Bedrock API is done via the AWS SDK for Python: [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\n",
    "\n",
    "#### Use different clients\n",
    "The boto3 provides different clients for Amazon Bedrock to perform different actions. The actions for [`InvokeModel`](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html) and [`InvokeModelWithResponseStream`](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html) are supported by Amazon Bedrock Runtime where as other operations, such as [ListFoundationModels](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ListFoundationModels.html), are handled via [Amazon Bedrock client](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Operations_Amazon_Bedrock.html).\n",
    "\n",
    "\n",
    "#### Use the default credential chain\n",
    "\n",
    "If you are running this notebook from [Amazon Sagemaker Studio](https://aws.amazon.com/sagemaker/studio/) and your Sagemaker Studio [execution role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) has permissions to access Bedrock you can just run the cells below as-is. This is also the case if you are running these notebooks from a computer whose default AWS credentials have access to Bedrock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "311253c1-f0d3-44dc-9fb4-19d28468286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1005e7f4-5d97-4dd3-bd26-7e551266c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock_control_plane = boto3.client('bedrock', region_name='us-west-2')\n",
    "boto3_bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "240183e7-134d-425e-a3aa-6d1b273ff73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using us inference profile see: https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html\n",
    "MICRO_MODEL_ID = \"us.amazon.nova-micro-v1:0\"\n",
    "LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "PRO_MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "CLAUDE_SONNET_MODEL_ID=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ff7b4-334b-4032-9a67-724163aa07cd",
   "metadata": {},
   "source": [
    "#### Validate the connection\n",
    "\n",
    "We can check the client works by trying out the `list_foundation_models()` method, which will tell us all the models available for us to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4b4f02d-4824-4e75-81b2-f271d788b385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon.nova-pro-v1:0',\n",
       " 'amazon.nova-lite-v1:0',\n",
       " 'amazon.nova-micro-v1:0',\n",
       " 'anthropic.claude-3-5-sonnet-20241022-v2:0:18k',\n",
       " 'anthropic.claude-3-5-sonnet-20241022-v2:0:51k',\n",
       " 'anthropic.claude-3-5-sonnet-20241022-v2:0:200k',\n",
       " 'anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
       " 'anthropic.claude-3-5-haiku-20241022-v1:0',\n",
       " 'anthropic.claude-instant-v1:2:100k',\n",
       " 'anthropic.claude-instant-v1',\n",
       " 'anthropic.claude-v2:0:18k',\n",
       " 'anthropic.claude-v2:0:100k',\n",
       " 'anthropic.claude-v2:1:18k',\n",
       " 'anthropic.claude-v2:1:200k',\n",
       " 'anthropic.claude-v2:1',\n",
       " 'anthropic.claude-v2',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0:28k',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0:200k',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0:48k',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0:200k',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0',\n",
       " 'anthropic.claude-3-opus-20240229-v1:0:12k',\n",
       " 'anthropic.claude-3-opus-20240229-v1:0:28k',\n",
       " 'anthropic.claude-3-opus-20240229-v1:0:200k',\n",
       " 'anthropic.claude-3-opus-20240229-v1:0',\n",
       " 'anthropic.claude-3-5-sonnet-20240620-v1:0:18k',\n",
       " 'anthropic.claude-3-5-sonnet-20240620-v1:0:51k',\n",
       " 'anthropic.claude-3-5-sonnet-20240620-v1:0:200k',\n",
       " 'anthropic.claude-3-5-sonnet-20240620-v1:0']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model['modelId'] for model in boto3_bedrock_control_plane.list_foundation_models()['modelSummaries'] if 'anthropic' in model['modelId'] or model['modelId'].startswith('amazon.nova')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0a0c8-598e-4710-a9ab-9f2f64a72867",
   "metadata": {},
   "source": [
    "### InvokeModel body and output\n",
    "\n",
    "The invoke_model() method of the Amazon Bedrock runtime client (InvokeModel API) will be the primary method we use for most of our Text Generation and Processing tasks\n",
    "\n",
    "Although the method is shared, the format of input and output varies depending on the foundation model used - as described below:\n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"system\": [\n",
    "    {\n",
    "      \"text\": string\n",
    "    }\n",
    "  ],\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",# first turn should always be the user turn\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": string\n",
    "        },\n",
    "        {\n",
    "          \"image\": {\n",
    "            \"format\": \"jpeg\"| \"png\" | \"gif\" | \"webp\",\n",
    "            \"source\": {\n",
    "              \"bytes\": \"base64EncodedImageDataHere...\"#  base64-encoded binary\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"video\": {\n",
    "            \"format\": \"mkv\" | \"mov\" | \"mp4\" | \"webm\" | \"three_gp\" | \"flv\" | \"mpeg\" | \"mpg\" | \"wmv\",\n",
    "            \"source\": {\n",
    "            # source can be s3 location of base64 bytes based on size of input file. \n",
    "               \"s3Location\": {\n",
    "                \"uri\": string, #  example: s3://my-bucket/object-key\n",
    "                \"bucketOwner\": string #  (Optional) example: 123456789012)\n",
    "               }\n",
    "              \"bytes\": \"base64EncodedImageDataHere...\" #  base64-encoded binary\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": string # prefilling assistant turn\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    " \"inferenceConfig\":{ # all Optional\n",
    "    \"max_new_tokens\": int, #  greater than 0, equal or less than 5k (default: dynamic*)\n",
    "    \"temperature\": float, # greater then 0 and less than 1.0 (default: 0.7)\n",
    "    \"top_p\": float, #  greater than 0, equal or less than 1.0 (default: 0.9)\n",
    "    \"top_k\": int #  0 or greater (default: 50)\n",
    "    \"stopSequences\": [string]\n",
    "  },\n",
    "  \"toolConfig\": { #  all Optional\n",
    "        \"tools\": [\n",
    "                {\n",
    "                    \"toolSpec\": {\n",
    "                        \"name\": string # menaingful tool name (Max char: 64)\n",
    "                        \"description\": string # meaningful description of the tool\n",
    "                        \"inputSchema\": {\n",
    "                            \"json\": { # The JSON schema for the tool. For more information, see JSON Schema Reference\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    <args>: { # arguments \n",
    "                                        \"type\": string, # argument data type\n",
    "                                        \"description\": string # meaningful description\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    string # args\n",
    "                                ]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "   \"toolChoice\": \"any\" //Amazon Nova models ONLY support tool choice of \"any\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The following are required parameters.\n",
    "\n",
    "* `system` – (Optional) The system prompt for the request.\n",
    "    A system prompt is a way of providing context and instructions to Amazon Nova, such as specifying a particular goal or role.\n",
    "* `messages` – (Required) The input messages.\n",
    "    * `role` – The role of the conversation turn. Valid values are user and assistant. \n",
    "    * `content` – (required) The content of the conversation turn.\n",
    "        * `type` – (required) The type of the content. Valid values are image, text. , video\n",
    "            * if chosen text (text content)\n",
    "                * `text` - The content of the conversation turn. \n",
    "            * If chosen Image (image content)\n",
    "                * `source` – (required) The base64 encoded image bytes for the image.\n",
    "                * `format` – (required) The type of the image. You can specify the following image formats. \n",
    "                    * `jpeg`\n",
    "                    * `png`\n",
    "                    * `webp`\n",
    "                    * `gif`\n",
    "            * If chosen video: (video content)\n",
    "                * `source` – (required) The base64 encoded image bytes for the video or S3 URI and bucket owner as shown in the above schema\n",
    "                * `format` – (required) The type of the video. You can specify the following video formats. \n",
    "                    * `mkv`\n",
    "                    *  `mov`  \n",
    "                    *  `mp4`\n",
    "                    *  `webm`\n",
    "                    *  `three_gp`\n",
    "                    *  `flv`  \n",
    "                    *  `mpeg`  \n",
    "                    *  `mpg`\n",
    "                    *  `wmv`\n",
    "* `inferenceConfig`: These are inference config values that can be passed in inference.\n",
    "    * `max_new_tokens` – (Optional) The maximum number of tokens to generate before stopping.\n",
    "        Note that Amazon Nova models might stop generating tokens before reaching the value of max_tokens. Maximum New Tokens value allowed is 5K.\n",
    "    * `temperature` – (Optional) The amount of randomness injected into the response.\n",
    "    * `top_p` – (Optional) Use nucleus sampling. Amazon Nova computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both.\n",
    "    * `top_k` – (Optional) Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses.\n",
    "    * `stopSequences` – (Optional) Array of strings containing step sequences. If the model generates any of those strings, generation will stop and response is returned up until that point. \n",
    "    * `toolConfig` – (Optional) JSON object following ToolConfig schema,  containing the tool specification and tool choice. This schema is the same followed by the Converse API\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65c8d5-3cce-4b72-8a0e-d4a1ac632b69",
   "metadata": {},
   "source": [
    "## 3 Document Understanding [Only Applicable using ConverseAPI)\n",
    "\n",
    "The Amazon Nova models allow users to include document(s) in the payload through ConverseAPI document support, which can be provided in bytes in the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d732083-5e4e-4b67-99b5-9bb557184aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_file=\"manuals/XC90_owners_manual_MY06_EN_tp8193.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "486051cf-ea74-4cb0-97fe-0e0452e549f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"manuals/XC90_owners_manual_MY06_EN_tp8193.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f996ca437d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(manual_file, width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6646e67-9ca8-4449-a470-8e9db059ae55",
   "metadata": {},
   "source": [
    "### 3.1 Split & Compress documents\n",
    "Any text documents (csv, xls, xlsx, html, txt, md, or doc) that you include in Nova must not exceed 4.5MB per document. All included media documents, including pdf and docx files, must not exceed 18MB in total. You can include a maximum of 5 documents. We split the documents into 50 pages sub documents and compress them removing annotations and reducing image quality. The reduced quality is still more than enough for Nova to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6baf74d5-cd23-4e0f-8fa0-eeb0bf72b28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.11/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fa89e68-9794-48dc-9c5d-4a5041154acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf(pdf_path, doc_size_in_pages=50):\n",
    "    from PyPDF2 import PdfReader, PdfWriter\n",
    "    import os\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = 'manuals'\n",
    "    \n",
    "    # Use absolute path for reading\n",
    "    pdf = PdfReader(os.path.abspath(pdf_path))\n",
    "    total_pages = len(pdf.pages)\n",
    "    \n",
    "    # Calculate number of documents needed\n",
    "    num_documents = (total_pages + doc_size_in_pages - 1) // doc_size_in_pages\n",
    "    \n",
    "    filenames = []\n",
    "    \n",
    "    for doc_num in range(num_documents):\n",
    "        pdf_writer = PdfWriter()\n",
    "        start_page = doc_num * doc_size_in_pages\n",
    "        end_page = min(start_page + doc_size_in_pages, total_pages)\n",
    "        \n",
    "        # Add pages for this chunk\n",
    "        for page_num in range(start_page, end_page):\n",
    "            pdf_writer.add_page(pdf.pages[page_num])\n",
    "        \n",
    "        # Create output filename\n",
    "        output_filename = f'{output_dir}/{pdf_path.split(\"/\")[-1].split(\".\")[0]}_{end_page}.pdf'\n",
    "        \n",
    "        # Write the PDF\n",
    "        with open(output_filename, 'wb') as out:\n",
    "            pdf_writer.write(out)\n",
    "            print(f'Created: {output_filename}')\n",
    "            filenames.append(output_filename)\n",
    "    \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "008d85e8-c6f1-445e-8100-bd6b65c37427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: manuals/XC90_owners_manual_MY06_EN_tp8193_60.pdf\n",
      "Created: manuals/XC90_owners_manual_MY06_EN_tp8193_120.pdf\n",
      "Created: manuals/XC90_owners_manual_MY06_EN_tp8193_180.pdf\n",
      "Created: manuals/XC90_owners_manual_MY06_EN_tp8193_240.pdf\n",
      "Created: manuals/XC90_owners_manual_MY06_EN_tp8193_254.pdf\n"
     ]
    }
   ],
   "source": [
    "doc_size_in_pages=60\n",
    "splitted_file_names=split_pdf(manual_file, doc_size_in_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d54013f-4a38-448c-9dee-9eaa3b02b54f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:6\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "directory_path=\"compressed_manuals\"\n",
    "if not os.path.exists(directory_path):\n",
    "    # Create the directory\n",
    "       os.makedirs(directory_path)\n",
    "        print(f\"Directory created: {directory_path}\")\n",
    "else:\n",
    "        print(f\"Directory already exists: {directory_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b72f05dd-2aa7-4058-9315-7171d5955341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def remove_annotations(page):\n",
    "    if \"/Annots\" in page:\n",
    "        del page[\"/Annots\"]\n",
    "    return page\n",
    "\n",
    "def compress_images_in_pdf(page):\n",
    "    if \"/Resources\" in page and \"/XObject\" in page[\"/Resources\"]:\n",
    "        xObject = page[\"/Resources\"][\"/XObject\"].get_object()\n",
    "        \n",
    "        for obj in xObject:\n",
    "            if xObject[obj][\"/Subtype\"] == \"/Image\":\n",
    "                size = (xObject[obj][\"/Width\"], xObject[obj][\"/Height\"])\n",
    "                data = xObject[obj].get_data()\n",
    "                \n",
    "                if xObject[obj][\"/ColorSpace\"] == \"/DeviceRGB\":\n",
    "                    mode = \"RGB\"\n",
    "                else:\n",
    "                    mode = \"P\"\n",
    "                \n",
    "                if \"/Filter\" in xObject[obj]:\n",
    "                    if xObject[obj][\"/Filter\"] == \"/FlateDecode\":\n",
    "                        try:\n",
    "                            img = Image.frombytes(mode, size, data)\n",
    "                            # Convert P mode to RGB before saving as JPEG\n",
    "                            if img.mode == 'P':\n",
    "                                img = img.convert('RGB')\n",
    "                            \n",
    "                            img_compressed = io.BytesIO()\n",
    "                            img.save(img_compressed, format=\"JPEG\", quality=50, optimize=True)\n",
    "                            xObject[obj]._data = img_compressed.getvalue()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Warning: Could not compress image: {str(e)}\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "def deep_compress_pdf(input_file_path, output_file_path):\n",
    "    reader = PdfReader(input_file_path)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    for page in reader.pages:\n",
    "        # Remove annotations\n",
    "        page = remove_annotations(page)\n",
    "        # Compress images\n",
    "        compress_images_in_pdf(page)\n",
    "        writer.add_page(page)\n",
    "\n",
    "    writer._compress = True\n",
    "    \n",
    "    with open(output_file_path, \"wb\") as output_file:\n",
    "        writer.write(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d91dfc5-50a9-433e-a4e5-8e07ed439d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os\n",
    "compressed_file_names=[]\n",
    "for i in splitted_file_names:\n",
    "    deep_compress_pdf(i, \"compressed_\"+i)\n",
    "    compressed_file_names.append(\"compressed_\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e61a2809-0b99-46f9-b6e4-996cb5b15b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compressed_manuals/XC90_owners_manual_MY06_EN_tp8193_60.pdf',\n",
       " 'compressed_manuals/XC90_owners_manual_MY06_EN_tp8193_120.pdf',\n",
       " 'compressed_manuals/XC90_owners_manual_MY06_EN_tp8193_180.pdf',\n",
       " 'compressed_manuals/XC90_owners_manual_MY06_EN_tp8193_240.pdf',\n",
       " 'compressed_manuals/XC90_owners_manual_MY06_EN_tp8193_254.pdf']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ed346-cb9a-4ffc-941b-15818a67ebd5",
   "metadata": {},
   "source": [
    "### 4.2 Prepare Payload\n",
    "Now we can prepare the payload to contain all the compressed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc402ec2-5b74-40dd-9d0a-b372b205c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files in doc_bytes array\n",
    "doc_bytes_list = []\n",
    "for splitted_file_name in splitted_file_names[:5]: #use compressed_file_names if any file is bigger than 4.5MB (limits might increase in the future)\n",
    "    with open(splitted_file_name, \"rb\") as file:\n",
    "        doc_bytes_list.append(file.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "290bccf7-dea4-432b-aae8-7cab24041eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"manuals/temp.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9974ecb7d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test if the partial documents are saved correctly\n",
    "with open('manuals/temp.pdf', \"wb\") as file:\n",
    "    file.write(doc_bytes_list[0])\n",
    "#display temp.pdf file\n",
    "IFrame(\"manuals/temp.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "796de98c-7976-449f-a391-6e6170efdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdf_request(doc_bytes_list, text):\n",
    "    # Create document content list by iterating through doc_bytes in the list\n",
    "    document_content = [\n",
    "        {\n",
    "            \"document\": {\n",
    "                \"format\": \"pdf\",\n",
    "                \"name\": f\"DocumentPDFmessages{i}\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": doc_bytes\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for i, doc_bytes in enumerate(doc_bytes_list)\n",
    "    ]\n",
    "    \n",
    "    # Add the text question at the end\n",
    "    document_content.append({\n",
    "        \"text\": text\n",
    "    })\n",
    "    \n",
    "    # Create the final messages structure\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": document_content\n",
    "    }]\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20dc9472-66d3-43f0-b5cd-137fdfdf03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=[{\"text\": \"Act as a driving manual assistant. When the user asks a question, answer only based on the documents provided. Document pages are located at the left or right lower corners of each page. Give a reference to do document section.\"}]\n",
    "\n",
    "user_prompts= [\"Can you switch the control display on/off?\",  \"How can I call from the memory?\", \"Where are the side airbags located?\",\"Where is the on/off button of the audio panel located with respect to keypad of audio panel?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "583b8cd1-0a43-4e93-b768-f9d9fd1e95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Response Content Text]\n",
      "The on/off button of the audio panel is located above the keypad of the audio panel. (Page 199)\n"
     ]
    }
   ],
   "source": [
    "messages=build_pdf_request(doc_bytes_list, user_prompts[3]) \n",
    "inf_params = {\"maxTokens\": 1024, \"topP\": 0.1, \"temperature\": 0}\n",
    "\n",
    "model_response = boto3_bedrock_runtime.converse(modelId=PRO_MODEL_ID, system=system_prompt,\n",
    "                                 messages=messages, \n",
    "                                 inferenceConfig=inf_params)\n",
    "\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(model_response['output']['message']['content'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
